---
link: https://zhuanlan.zhihu.com/p/386493135
title: 如何做大文件上传
description: 背景文件上传是个非常普遍的场景，特别是在一些资源管理相关的业务中(比如网盘)。在文件比较大的时候，普通的上传方式可能会遇到以下四个问题。 文件上传超时：原因是前端请求框架认限制最大请求时长，或者是 ngin…
keywords: 文件上传,大文件传输,前端开发
author: 神马翔不会写Java的前端不是好运维
date: 2021-07-05T09:56:00.000Z
publisher: 知乎专栏
stats: paragraph=63 sentences=8, words=238
---
文件上传是个非常普遍的场景，特别是在一些资源管理相关的业务中(比如网盘)。在文件比较大的时候，普通的上传方式可能会遇到以下四个问题。

对于前两点，虽说可以通过一定的配置来解决，但有时候也不会那么顺利，毕竟调大这些参数会对后台造成一定的压力，需要兼顾实际场景。只是上传慢的话忍一忍是可以接受的，但是失败后重头开始，在网络环境差的时候简直就是灾难。

针对遇到的这些问题，有比较成熟的解决方案。该方案可以简答的概括为**切片上传 + 秒传**。

**切片上传是指将一个大文件切割为若干个小文件，分为多个请求依次上传，后台再将文件碎片拼接为一个完整的文件，即使某个碎片上传失败，也不会影响其它文件碎片，只需要重新上传失败的部分就可以了。而且多个请求一起发送文件，提高了传输速度的上限**。

**秒传指的是文件在传输之前计算其内容的散列值，也就是 Hash 值，将该值传到后台，如果后台存在 Hash 值一致的文件，认为该文件上传完成**。

该方案很巧妙的解决了上述提出的一系列问题，也是目前资源管理类系统的通用解决方案。

本文会梳理大文件上传中的一些知识点，并根据上述方案，实现一个切片上传 + 秒传的前后端，前端我用 react 实现，后台用的 java。相关代码我放在 [github](https://link.zhihu.com/?target=https%3A//github.com/shenmaxg/file-upload-react) 上。

最终实现的效果如下：

## 文件上传原理

最开始 XMLHttpRequest 是不支持传输二进制文件的。文件只能使用表单的方式上传，我们需要写一个 Form，然后将 enctype 设置为 multipart/form-data。此时的 Content-Type 为 multipart/form-data，并且会自动跟一个 boundary 字符串，该字符串用于隔离不同的字段。

所以 multipart/form-data 既可以上传文件，也可以上传键值对，每个元素由 boundary 分隔放在请求的 body 中。

后来 XMLHttpRequest 升级为 Level 2 之后，新增了 FormData 对象，用于模拟表单数据，并且支持发送和接收二进制数据。我们目前使用的文件上传基本都是基于 XMLHttpRequest Level 2。使用 XMLHttpRequest 后文件上传的报文和上述的一致。写法如下。

需要注意的是，**xhr.send(data)中 data 参数的数据类型会影响请求头部 content-type 的值**。我们上传文件，data 的类型是 FormData，此时 content-type 默认值为 multipart/form-data; boundary=[xxx]。当然，但如果用 xhr.setRequestHeader() 手动设置了中 content-type 的值，以用户设定的为准。因此，**在上传文件场景下，不必设置 content-type 的值，浏览器会根据文件类型自动配置**

## 文件切片

**文件切片和核心是使用 Blob 对象的 slice 方法。**

我们使用 \ 的方式获得一个 File 对象。**File 继承于 Blob**。所以我们也可以使用 slice 方法对文件进行切割。Blob 对象的 slice 方法会返回一个新的 Blob 对象，包含了源 Blob 对象中制定范围内的数据。

start 和 end 代表 Blob 里的下标，表示被拷贝进新的 Blob 的字节的起始位置和结束位置。contentType 会给新的 Blob 赋予一个新的文档类型，很少使用。

在分片上传场景中，我们一般会规定一个切边大小，根据这个大小对文件进行分割。除了这种固定大小的方案外，还有的文章中会**根据当前的网络情况动态的调整切片的大小，类似于 TCP 的拥塞控制**。本文为了简单，实用固定大小的切片。代码如下。我定义了 FileChunk 对象，这个对象中除了包含切片本身外，还额外存放了一些数据，比如切边在源文件中的起止位置，这么做是为了方便后台拿到切片数据后做文件合并的。

## 文件合并

文件合并方案有这么几种。

这三种方案中，前两种都是比较通用的方案，且都是可行的，方案一的代价在于多发了一次请求，极小的概率会出现文件上传成功，但是合并请求发送失败的情况，好处就是流程比较清晰。方案二比方案一少了一次请求，代价是每次上传结束后需要判断当前切片是否是最后一个切片，需要在数据库中维护切片的状态。

方案三比较好的，相当于直接省略了文件合并的步骤，速度比较快。但是不用语言的实现难度不同。如果没有合适的 API 的话，自己实现的难度很大。由于我后台是用 java 编写的。我们可以充分利用 java 中的 RandomAccessFile 这个类。

RandomAccessFile 既可以读取文件内容，也可以向文件输出数据。它最大的特点就是**支持 "随机访问" 的方式，程序快可以直接跳转到文件的任意地方来读写数据**。在切片上传场景下，由于请求是并行发送的，后台会一次性收到大量的切片文件。每个切片文件都携带了当前切片在总文件中的位置信息，我们使用 RandomAccessFile 的 seek 方法定位到切片的起始位置，然后将切片从这个位置开始写入。这也是 RandomAccessFile 的一个重要使用场景。

## 显示进度

旧版的 XMLHttpRequest 是不支持显示进度的，升级为 Level 2 之后，有一个 progress 事件，用来返回进度信息。这也是为什么该场景下推荐使用 xhr ，而不使用 fetch 的原因。**fetch 不提供相关的接口，我们无法获得文件的上传进度**。

**我们可以通过 onprogress 事件来实时显示进度，默认情况下这个事件每 50ms 触发一次**。需要注意的是，上传过程和下载过程触发的是不同对象的 onprogress 事件：上传触发的是 xhr.upload 对象的 onprogress 事件，下载触发的是 xhr对象的 onprogress 事件。

这个事件有一些属性。event.total 是需要传输的总字节，event.loaded 是已经传输的字节。

由于在切片上传场景下，我们获得的是单个切片的上传进度，所以一般需要将单个的进度进行累加，用于计算总的进度，具体代码就不贴了。当然，我们也可以兼顾两种方式。我在大圣老师的文章中找到一种很好的显示进度的方式。将每个切片算作是一个小方块，通过颜色表示进度，非常直观。

## 断点续传

切片上传有一个很好的特性就是上传过程可以中断，不论是人为的暂停还是由于网络环境导致的链接的中断，都只会影响到当前的切片，而不会导致整体文件的失败，下次开始上传的时候可以从失败的切片继续上传。

我们为当前的上传操作增加一个停止按钮，用于模拟网络错误导致的上传失败。一个请求能被取消的前提是，我们需要将未收到响应的请求保存在一个列表中，然后依次调用每个 xhr 对象的 abort 方法。调用这个方法后，xhr 对象会停止触发事件，将请求的 status 置为 0，并且无法访问任何与响应有关的属性。

从后端的角度看，一个上传请求被取消，意味着当前浏览器不会再向后端传输数据流，后端此时会报错，如下，错误信息也很清楚，就是文件还没到末尾就被客户端中断。当前文件切片写入失败。

接下来就是如何实现断点续传，关键点是**后端需要记录文件文件切片的信息**。用户在上传一个文件之前，先询问服务器，当前文件是否存在已经上传完毕的切片，如果存在的话，需要返回切片信息。前端根据返回的信息，调整当前的进度，上传未完成的切片。

具体的做法是，切片上传完成后，后端记录当前切片的详细信息。

前端在文件上传之前，多加一个步骤，那就是从后端获得已经存在的切片文件。这里我们先用文件名来查询，这只是临时方案，文件名并不能作为文件的唯一标志，后续我们会改为使用文件 Hash 的方式来查询。

如果存在已经上传好的切片，将这些切片的状态更新为成功，修改进度为 100，后续发送请求的时候会过滤掉状态为成功的切片。

如此，就完成了一个文件的断点续传工作，演示如下。

## 限制请求个数

我在尝试将一个 5G 大小的文件上传的时候，发现前端浏览器出现卡死现象，原因是切片文件过多，浏览器一次性创建了太多了 xhr 请求。这是没有必要的，拿 chrome 浏览器来说，默认的并发数量只有 6，过多的请求并不会提升上传速度，反而是给浏览器带来了巨大的负担。因此，我们有必要限制前端请求个数。

思路比较简单，先**创建最大并发数的请求，然后在请求的回调函数中再次创建请求，直到全部请求都发出为止**。

## 并发重试

切片上传的过程中，我们有可能因为各种原因导致某个切片上传失败，比如网络抖动、后端文件进程占用等等。对于这种情况，最好的方案就是为切片上传增加一个失败重试机制。由于切片不大，重试的代价很小，我们**设定一个最大重试次数**，如果在次数内依然没有上传成功，认为上传失败。

具体的做法就是改造 requestWithLimit 方法。

定义一个 retryArr 数组，用于记录文件上传失败的次数。改造 catch 方法，一个文件切片上传报错时候，先判断 retryArr 中给切片的错误次数是否达到最大值，如果没有的话，清空当前切片上传进度，重新请求。相应的，我们之前只上传处于 READY 状态的切片，现在要稍微调整下，处于 ERROR 状态的切片也获得上传资格。

后台坐下设置，每个切片第一次上传一定失败，会触发重传机制，如下所示。每个切片都会上传两次，发现进度显示的有点魔性，抽空优化吧。

秒传指的是文件如果在后台已经存了一份，就没必要再次上传了，直接返回上传成功。在体量比较大的应用场景下，秒传是个必要的功能，既能提高用户上传体验，又能节约自己的硬盘资源。

**秒传的关键在于计算文件的唯一性标识**。

文件的不同不是命名的差异，而是内容的差异，所以我们将整个文件的二进制码作为入参，计算 Hash 值，将其作为文件的唯一性标识。一般而言，这样做就够了，但是摘要算法是存在碰撞概率的，我们如果想要再严谨点的话，可以将文件大小也作为衡量指标，**只有文件摘要和文件大小同时相等，才认为是相同的文件**。

文件 Hash 值的计算是 CPU 密集型任务，线程在计算 Hash 值的过程中，页面处于假死状态。所以，该任务一定不能在当前线程进行，我们**使用 Web Worker 执行计算任务**。

Web Worker 是 HTML5 标准的一部分，它允许一段 JavaScript 程序运行在主线程之外的另外一个线程中。这样计算任务就不会影响到当前线程的渲染任务。

目前网上有很多 Web Worker 使用方案，我使用的前端框架是 umi，直接配置下就好了。

Web Worker 是一段单独的 JS 程序，它和当前线程间使用 postMessage 的方式进行通讯。

**如何快速计算文件的 md5 值呢？ 我们使用 js-spark-md5 这个库**

js-spark-md5 是号称全宇宙最快的前端类包。我在本机测下来，计算 1G 文件大概 15 秒，确实很快。由于是在 Web Worker 中计算，需要将 spark-md5.min.js 放到静态资源目录下，方便引用。

此时前端上传文件的流程是这样的。

后端也做下调整，上传文件的接口，需要在文件全部上传完毕后，记录下文件的详细信息，包括 md5 值，作为后续文件秒传的依据。

判断秒传和断点续传的代码可以合并为一个接口，作为文件上传的前置接口。

秒传功能由于需要计算 Hash 值，会导致整体上传速度变慢，但是和大文件上传需要的耗时以及消耗的流量比起来，是一种性价比很高的选择。

如果觉得文件计算全量 Hash 比较慢的话，还有一种方式就是计算抽样 Hash，减少计算的字节数可以大幅度减少耗时，但是抽样 Hash 的结果不能作为文件的唯一性标识，抽样 Hash 的值如果和后端一致，前端再计算全量 Hash，如果和后端不一致，那么这个文件一定无法秒传，此时可以直接将文件上传，当然，上传之后还是需要计算全量 Hash 值的。这种方案在文件重复率较少的场景下是很好的，它能极大减少了前端的计算量，提高了速度，相当于转移了一部分工作到后端，也是不错的选择。

断点续传的重点是文件的切割与合并，整个上传流程需要前后端配合好，细节较多。秒传的关键是如何快速计算大文件的摘要信息。我们最后再梳理下文件上传的完整流程。

目前还有一些可以优化的点。

文章和代码都参考了如下几位大神的项目，建议大家看看。

**如果您觉得有所收获，就点个赞吧！**
